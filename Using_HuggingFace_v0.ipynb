{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2UXutvEvpUj"
   },
   "source": [
    "# Question Answering with BERT and HuggingFace\n",
    "\n",
    "This notebook shows a simple example of using pre-trained BERT models from HuggingFace. What will be shown:\n",
    "- Loading a pre-trained model for Question Answering.\n",
    "- Evaluating the model of some simple examples\n",
    "- Fine-tune training the model on a new dataset\n",
    "- Evaluating the fine-tuned trained model\n",
    "\n",
    "From pipelines from HuggingFace we can find pre-trained transformer models for a variety of tasks like sentiment analysis, question answers, etc --> [Link](https://huggingface.co/docs/transformers/v4.21.0/en/main_classes/pipelines)\n",
    "\n",
    "Two parameters will be give to the pipeline: task (at the moment has 16 options) and model (a model identifier or an actual instance of a pretrained model inheriting from PreTrainedModel for PyTorch). When calling the pipeline for a specific model, sometimes the task parameter can be ignored as the model already has that information.\n",
    "\n",
    "\n",
    "For question answering we can refer to --> [Link](https://huggingface.co/docs/transformers/main_classes/pipelines#the-pipeline-abstraction) and we use this model [Model](https://huggingface.co/distilbert-base-cased-distilled-squad) we can see from the documentation of the model what it has been trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7rW5HyNyv3YC"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\HP\\anaconda3\\envs\\transformer\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = pipeline(task=\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we chose not use the pipleline, we have to use a tokenizer to process the sentence first. Then 'with no grad' we pass the dictionary returned by the tokenizer to the model. The model link gives an example [Link](https://huggingface.co/distilbert-base-cased-distilled-squad). The examples don't have much details usually and you would need to try a few times to become familiar how they actually work. \n",
    "\n",
    "Sometimes even the format of the returned parameters from the model are not discussed or shown!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "I have to pick up the kids from the school at 5 in the afternoon today. But tomorrow I have to do that two hours earlier\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.3463056683540344, 'start': 47, 'end': 65, 'answer': '5 in the afternoon'}, {'score': 0.4067622125148773, 'start': 47, 'end': 65, 'answer': '5 in the afternoon'}, {'score': 0.8328907489776611, 'start': 33, 'end': 43, 'answer': 'the school'}]\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "            \"When should I be at the school today?\",\n",
    "             \"What time should I pick them up tomorrow?\",\n",
    "             \"From where should I pick them up?\"\n",
    "          ]\n",
    "\n",
    "answers = QA(question = questions, context = context)\n",
    "\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model returns a list of dictionaries. The text of the answer can be retrieved by the key 'answer' and the score given by the 'score'. Location of the answer is also return by 'start' and 'end' key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When should I be at the school today? \n",
      ">> 5 in the afternoon\n",
      "Correctness score: 0.3463056683540344\n",
      "\n",
      "What time should I pick them up tomorrow? \n",
      ">> 5 in the afternoon\n",
      "Correctness score: 0.4067622125148773\n",
      "\n",
      "From where should I pick them up? \n",
      ">> the school\n",
      "Correctness score: 0.8328907489776611\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question, answer in zip(questions, answers):\n",
    "    print(question, \"\\n>> \" + answer['answer'] + \"\\nCorrectness score: \" + str(answer['score']) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, OK but not so smart perhaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple test 2\n",
    "\n",
    "A paragraph from wikipedia about San Francisco's 1906 earth quake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "The 1906 earthquake preceded the development of the Richter magnitude scale by three decades. \n",
    "The most widely accepted estimate for the magnitude of the quake on the modern moment magnitude scale is 7.9. \n",
    "Values from 7.7 to as high as 8.3 have been proposed.\n",
    "According to findings published in the Journal of Geophysical Research, \n",
    "severe deformations in the earth's crust took place both before and after the earthquake's impact. \n",
    "Accumulated strain on the faults in the system was relieved during the earthquake, \n",
    "which is the supposed cause of the damage along the 450-kilometre-long (280 mi) segment of the San Andreas plate boundary.\n",
    "The 1906 rupture propagated both northward and southward for a total of 296 miles (476 km).\n",
    "Shaking was felt from Oregon to Los Angeles, and as far inland as central Nevada.\n",
    "\n",
    "A strong foreshock preceded the main shock by about 20 to 25 seconds. \n",
    "The strong shaking of the main shock lasted about 42 seconds. \n",
    "There were decades of minor earthquakes, more than at any other time in the historical record for northern California, \n",
    "before the 1906 quake. Previously interpreted as precursory activity to the 1906 earthquake, \n",
    "they have been found to have a strong seasonal pattern,\n",
    "and are now believed to be due to large seasonal sediment loads in coastal bays that overlie faults as a result of \n",
    "the erosion caused by hydraulic mining in the later years of the California Gold Rush.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was Ritcher scale known in 1906? \n",
      ">> The 1906 rupture propagated both northward and southward\n",
      "Correctness score: 0.021126631647348404\n",
      "\n",
      "What is the magnitude estimate of 1906 earthquake? \n",
      ">> 7.9\n",
      "Correctness score: 0.763514518737793\n",
      "\n",
      "What is the highest proposed magnitude estimate of 1906 earthquake? \n",
      ">> 7.9\n",
      "Correctness score: 0.37356507778167725\n",
      "\n",
      "How long did the main shock last? \n",
      ">> 42 seconds\n",
      "Correctness score: 0.6660254597663879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\"Was Ritcher scale known in 1906?\",\n",
    "             \"What is the magnitude estimate of 1906 earthquake?\",\n",
    "             \"What is the highest proposed magnitude estimate of 1906 earthquake?\",\n",
    "             \"How long did the main shock last?\"]\n",
    "\n",
    "answers = QA(question=questions, context=context)\n",
    "\n",
    "for question, answer in zip(questions, answers):\n",
    "    print(question, \"\\n>> \" + answer['answer'] + \"\\nCorrectness score: \" + str(answer['score']) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained data evaluation\n",
    "\n",
    "We try to evaluate the performance of the model on [TyDi QA] (https://ai.google.com/research/tydiqa) dataset.\n",
    "\n",
    "Dataset has been downloaded locally from [Link](https://storage.googleapis.com/nlprefresh-public/tydiqa_data.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
       "        num_rows: 9211\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['passage_answer_candidates', 'question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
       "        num_rows: 1031\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './Data/tydiqa_data'\n",
    "tydiqa_data = load_from_disk(path)\n",
    "tydiqa_data"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C4_W3_1_Question_Answering_with_BERT_and_HuggingFace_Pytorch_tydiqa.ipynb",
   "provenance": [
    {
     "file_id": "1opdIFgplRcW7f-Hi_oLUHmoC5Cb2AtZZ",
     "timestamp": 1628789114198
    }
   ]
  },
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
